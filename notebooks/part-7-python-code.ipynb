{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Part 7: Python Code Generation\n",
    "## Training a model to write Python code\n",
    "\n",
    "In Parts 1-6, we built the complete LLM pipeline. Now let's apply it to something practical: **generating Python code**!\n",
    "\n",
    "This is how models like GitHub Copilot and CodeLlama work - they're language models trained on code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Why Code Generation is Interesting\n",
    "\n",
    "Code has special properties that make it different from natural language:\n",
    "\n",
    "1. **Strict syntax**: Missing a colon or wrong indentation breaks everything\n",
    "2. **Logical structure**: Functions, classes, loops have clear patterns\n",
    "3. **Verifiable output**: We can actually RUN the generated code!\n",
    "4. **Practical utility**: Code completion saves developers hours daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 1: Create a Python Code Dataset\n",
    "\n",
    "We'll create a curated dataset of Python code examples covering common patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code examples for training\n",
    "python_code_examples = '''\n",
    "# === BASIC FUNCTIONS ===\n",
    "\n",
    "def hello_world():\n",
    "    \"\"\"Print hello world.\"\"\"\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"Greet a person by name.\"\"\"\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "def add(a, b):\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a, b):\n",
    "    \"\"\"Subtract b from a.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def multiply(a, b):\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a, b):\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Return square of x.\"\"\"\n",
    "    return x * x\n",
    "\n",
    "def cube(x):\n",
    "    \"\"\"Return cube of x.\"\"\"\n",
    "    return x * x * x\n",
    "\n",
    "def power(base, exp):\n",
    "    \"\"\"Return base raised to exp.\"\"\"\n",
    "    return base ** exp\n",
    "\n",
    "def absolute(x):\n",
    "    \"\"\"Return absolute value.\"\"\"\n",
    "    if x < 0:\n",
    "        return -x\n",
    "    return x\n",
    "\n",
    "# === LIST OPERATIONS ===\n",
    "\n",
    "def sum_list(numbers):\n",
    "    \"\"\"Sum all numbers in a list.\"\"\"\n",
    "    total = 0\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    return total\n",
    "\n",
    "def average(numbers):\n",
    "    \"\"\"Calculate average of numbers.\"\"\"\n",
    "    if len(numbers) == 0:\n",
    "        return 0\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "def find_max(numbers):\n",
    "    \"\"\"Find maximum value in list.\"\"\"\n",
    "    if len(numbers) == 0:\n",
    "        return None\n",
    "    max_val = numbers[0]\n",
    "    for num in numbers:\n",
    "        if num > max_val:\n",
    "            max_val = num\n",
    "    return max_val\n",
    "\n",
    "def find_min(numbers):\n",
    "    \"\"\"Find minimum value in list.\"\"\"\n",
    "    if len(numbers) == 0:\n",
    "        return None\n",
    "    min_val = numbers[0]\n",
    "    for num in numbers:\n",
    "        if num < min_val:\n",
    "            min_val = num\n",
    "    return min_val\n",
    "\n",
    "def reverse_list(items):\n",
    "    \"\"\"Reverse a list.\"\"\"\n",
    "    return items[::-1]\n",
    "\n",
    "def count_items(items):\n",
    "    \"\"\"Count items in list.\"\"\"\n",
    "    return len(items)\n",
    "\n",
    "def first_element(items):\n",
    "    \"\"\"Get first element.\"\"\"\n",
    "    if len(items) == 0:\n",
    "        return None\n",
    "    return items[0]\n",
    "\n",
    "def last_element(items):\n",
    "    \"\"\"Get last element.\"\"\"\n",
    "    if len(items) == 0:\n",
    "        return None\n",
    "    return items[-1]\n",
    "\n",
    "def remove_duplicates(items):\n",
    "    \"\"\"Remove duplicates from list.\"\"\"\n",
    "    return list(set(items))\n",
    "\n",
    "def flatten(nested_list):\n",
    "    \"\"\"Flatten a nested list.\"\"\"\n",
    "    result = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            result.extend(flatten(item))\n",
    "        else:\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "# === STRING OPERATIONS ===\n",
    "\n",
    "def reverse_string(s):\n",
    "    \"\"\"Reverse a string.\"\"\"\n",
    "    return s[::-1]\n",
    "\n",
    "def is_palindrome(s):\n",
    "    \"\"\"Check if string is palindrome.\"\"\"\n",
    "    s = s.lower()\n",
    "    return s == s[::-1]\n",
    "\n",
    "def count_vowels(s):\n",
    "    \"\"\"Count vowels in string.\"\"\"\n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    count = 0\n",
    "    for char in s:\n",
    "        if char in vowels:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_words(s):\n",
    "    \"\"\"Count words in string.\"\"\"\n",
    "    words = s.split()\n",
    "    return len(words)\n",
    "\n",
    "def to_uppercase(s):\n",
    "    \"\"\"Convert to uppercase.\"\"\"\n",
    "    return s.upper()\n",
    "\n",
    "def to_lowercase(s):\n",
    "    \"\"\"Convert to lowercase.\"\"\"\n",
    "    return s.lower()\n",
    "\n",
    "def capitalize_words(s):\n",
    "    \"\"\"Capitalize each word.\"\"\"\n",
    "    return s.title()\n",
    "\n",
    "def remove_spaces(s):\n",
    "    \"\"\"Remove all spaces.\"\"\"\n",
    "    return s.replace(\" \", \"\")\n",
    "\n",
    "def replace_char(s, old, new):\n",
    "    \"\"\"Replace character in string.\"\"\"\n",
    "    return s.replace(old, new)\n",
    "\n",
    "# === NUMBER CHECKS ===\n",
    "\n",
    "def is_even(n):\n",
    "    \"\"\"Check if number is even.\"\"\"\n",
    "    return n % 2 == 0\n",
    "\n",
    "def is_odd(n):\n",
    "    \"\"\"Check if number is odd.\"\"\"\n",
    "    return n % 2 != 0\n",
    "\n",
    "def is_positive(n):\n",
    "    \"\"\"Check if number is positive.\"\"\"\n",
    "    return n > 0\n",
    "\n",
    "def is_negative(n):\n",
    "    \"\"\"Check if number is negative.\"\"\"\n",
    "    return n < 0\n",
    "\n",
    "def is_prime(n):\n",
    "    \"\"\"Check if number is prime.\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_perfect_square(n):\n",
    "    \"\"\"Check if n is perfect square.\"\"\"\n",
    "    if n < 0:\n",
    "        return False\n",
    "    root = int(n**0.5)\n",
    "    return root * root == n\n",
    "\n",
    "# === CLASSIC ALGORITHMS ===\n",
    "\n",
    "def factorial(n):\n",
    "    \"\"\"Calculate factorial of n.\"\"\"\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n - 1)\n",
    "\n",
    "def fibonacci(n):\n",
    "    \"\"\"Return nth Fibonacci number.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "def fibonacci_list(n):\n",
    "    \"\"\"Return first n Fibonacci numbers.\"\"\"\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    if n == 1:\n",
    "        return [0]\n",
    "    fibs = [0, 1]\n",
    "    for i in range(2, n):\n",
    "        fibs.append(fibs[-1] + fibs[-2])\n",
    "    return fibs\n",
    "\n",
    "def gcd(a, b):\n",
    "    \"\"\"Find greatest common divisor.\"\"\"\n",
    "    while b:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "def lcm(a, b):\n",
    "    \"\"\"Find least common multiple.\"\"\"\n",
    "    return a * b // gcd(a, b)\n",
    "\n",
    "def binary_search(arr, target):\n",
    "    \"\"\"Binary search for target in sorted array.\"\"\"\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "\n",
    "def bubble_sort(arr):\n",
    "    \"\"\"Sort array using bubble sort.\"\"\"\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\n",
    "def insertion_sort(arr):\n",
    "    \"\"\"Sort array using insertion sort.\"\"\"\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and arr[j] > key:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "    return arr\n",
    "\n",
    "def linear_search(arr, target):\n",
    "    \"\"\"Linear search for target.\"\"\"\n",
    "    for i, val in enumerate(arr):\n",
    "        if val == target:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# === DATA STRUCTURES ===\n",
    "\n",
    "class Stack:\n",
    "    \"\"\"Stack data structure.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "    \n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "    \n",
    "    def pop(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        return self.items.pop()\n",
    "    \n",
    "    def peek(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        return self.items[-1]\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.items) == 0\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.items)\n",
    "\n",
    "class Queue:\n",
    "    \"\"\"Queue data structure.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "    \n",
    "    def enqueue(self, item):\n",
    "        self.items.append(item)\n",
    "    \n",
    "    def dequeue(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        return self.items.pop(0)\n",
    "    \n",
    "    def front(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        return self.items[0]\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.items) == 0\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.items)\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Node for linked list.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "\n",
    "class LinkedList:\n",
    "    \"\"\"Singly linked list.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    \n",
    "    def append(self, data):\n",
    "        new_node = Node(data)\n",
    "        if not self.head:\n",
    "            self.head = new_node\n",
    "            return\n",
    "        current = self.head\n",
    "        while current.next:\n",
    "            current = current.next\n",
    "        current.next = new_node\n",
    "    \n",
    "    def prepend(self, data):\n",
    "        new_node = Node(data)\n",
    "        new_node.next = self.head\n",
    "        self.head = new_node\n",
    "    \n",
    "    def delete(self, data):\n",
    "        if not self.head:\n",
    "            return\n",
    "        if self.head.data == data:\n",
    "            self.head = self.head.next\n",
    "            return\n",
    "        current = self.head\n",
    "        while current.next:\n",
    "            if current.next.data == data:\n",
    "                current.next = current.next.next\n",
    "                return\n",
    "            current = current.next\n",
    "    \n",
    "    def find(self, data):\n",
    "        current = self.head\n",
    "        while current:\n",
    "            if current.data == data:\n",
    "                return True\n",
    "            current = current.next\n",
    "        return False\n",
    "\n",
    "# === FILE OPERATIONS ===\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"Read contents of a file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def write_file(filename, content):\n",
    "    \"\"\"Write content to a file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def append_file(filename, content):\n",
    "    \"\"\"Append content to a file.\"\"\"\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_lines(filename):\n",
    "    \"\"\"Read file as list of lines.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def count_lines(filename):\n",
    "    \"\"\"Count lines in a file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return len(f.readlines())\n",
    "\n",
    "# === DICTIONARY OPERATIONS ===\n",
    "\n",
    "def merge_dicts(dict1, dict2):\n",
    "    \"\"\"Merge two dictionaries.\"\"\"\n",
    "    result = dict1.copy()\n",
    "    result.update(dict2)\n",
    "    return result\n",
    "\n",
    "def get_keys(d):\n",
    "    \"\"\"Get all keys from dictionary.\"\"\"\n",
    "    return list(d.keys())\n",
    "\n",
    "def get_values(d):\n",
    "    \"\"\"Get all values from dictionary.\"\"\"\n",
    "    return list(d.values())\n",
    "\n",
    "def invert_dict(d):\n",
    "    \"\"\"Swap keys and values.\"\"\"\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "def filter_dict(d, keys):\n",
    "    \"\"\"Filter dictionary by keys.\"\"\"\n",
    "    return {k: v for k, v in d.items() if k in keys}\n",
    "\n",
    "# === LIST COMPREHENSIONS ===\n",
    "\n",
    "def squares(n):\n",
    "    \"\"\"Return squares from 1 to n.\"\"\"\n",
    "    return [x**2 for x in range(1, n+1)]\n",
    "\n",
    "def evens(n):\n",
    "    \"\"\"Return even numbers up to n.\"\"\"\n",
    "    return [x for x in range(n+1) if x % 2 == 0]\n",
    "\n",
    "def odds(n):\n",
    "    \"\"\"Return odd numbers up to n.\"\"\"\n",
    "    return [x for x in range(n+1) if x % 2 != 0]\n",
    "\n",
    "def filter_positive(numbers):\n",
    "    \"\"\"Filter positive numbers.\"\"\"\n",
    "    return [x for x in numbers if x > 0]\n",
    "\n",
    "def double_all(numbers):\n",
    "    \"\"\"Double all numbers.\"\"\"\n",
    "    return [x * 2 for x in numbers]\n",
    "\n",
    "# === ERROR HANDLING ===\n",
    "\n",
    "def safe_divide(a, b):\n",
    "    \"\"\"Safely divide with error handling.\"\"\"\n",
    "    try:\n",
    "        return a / b\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "def safe_int(s):\n",
    "    \"\"\"Safely convert string to int.\"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def safe_get(lst, index):\n",
    "    \"\"\"Safely get list element.\"\"\"\n",
    "    try:\n",
    "        return lst[index]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "# === DECORATORS ===\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Decorator to time function.\"\"\"\n",
    "    import time\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end-start:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def memoize(func):\n",
    "    \"\"\"Decorator for memoization.\"\"\"\n",
    "    cache = {}\n",
    "    def wrapper(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = func(*args)\n",
    "        return cache[args]\n",
    "    return wrapper\n",
    "\n",
    "# === GENERATORS ===\n",
    "\n",
    "def range_generator(n):\n",
    "    \"\"\"Generate numbers 0 to n-1.\"\"\"\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        yield i\n",
    "        i += 1\n",
    "\n",
    "def infinite_counter():\n",
    "    \"\"\"Infinite counter generator.\"\"\"\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "def fibonacci_generator():\n",
    "    \"\"\"Generate Fibonacci numbers.\"\"\"\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "'''\n",
    "\n",
    "print(f\"Training data: {len(python_code_examples):,} characters\")\n",
    "print(f\"Approximate lines: {python_code_examples.count(chr(10))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Step 2: Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build character vocabulary from code\n",
    "chars = sorted(set(python_code_examples))\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Characters include: letters, digits, punctuation, whitespace\")\n",
    "print(f\"\\nSample characters: {repr(''.join(chars[:30]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "block_size = 64  # Reduced from 128 for speed\n\ndef build_dataset(text, block_size, stoi):\n    data = [stoi[ch] for ch in text]\n    X, Y = [], []\n    for i in range(len(data) - block_size):\n        X.append(data[i:i + block_size])\n        Y.append(data[i + 1:i + block_size + 1])\n    return torch.tensor(X), torch.tensor(Y)\n\nX, Y = build_dataset(python_code_examples, block_size, stoi)\nprint(f\"Training examples: {len(X):,}\")\nprint(f\"Input shape: {X.shape}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Transformer Model for Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.shape[1]]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.W_qkv = nn.Linear(d_model, 3 * d_model, bias=False)\n",
    "        self.W_out = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, seq_len, d_model = x.shape\n",
    "        qkv = self.W_qkv(x).reshape(batch, seq_len, 3, self.n_heads, self.d_k)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        Q, K, V = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device), diagonal=1).bool()\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attention, V)\n",
    "        output = output.permute(0, 2, 1, 3).reshape(batch, seq_len, d_model)\n",
    "        return self.W_out(output)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.attention(self.ln1(x)))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class CodeLM(nn.Module):\n",
    "    \"\"\"Transformer for Python code generation.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers, block_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, block_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.ln_final = nn.LayerNorm(d_model)\n",
    "        self.output = nn.Linear(d_model, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.token_emb(x)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_final(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Create model - REDUCED size for fast demo\nd_model = 128  # Reduced from 256\nn_heads = 4    # Reduced from 8\nn_layers = 3   # Reduced from 6\n\nmodel = CodeLM(\n    vocab_size=vocab_size,\n    d_model=d_model,\n    n_heads=n_heads,\n    n_layers=n_layers,\n    block_size=block_size,\n    dropout=0.1\n).to(device)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(f\"Model parameters: {num_params:,}\")\n\n# Model scale context\nprint(f\"\\n--- Model Scale Context ---\")\nprint(f\"Our model:     ~{num_params/1_000_000:.1f}M parameters (SMALL for fast demo!)\")\nprint(f\"CodeLlama-7B:  7B parameters   ({7_000_000_000/num_params:.0f}x larger)\")\nprint(f\"GPT-4:         ~1T+ parameters ({1_000_000_000_000/num_params:.0f}x larger)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 5: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "def train(model, X, Y, epochs=1000, batch_size=32, lr=3e-4, checkpoint_path='../models/checkpoint_part7.pt', resume=True):\n    \"\"\"\n    Resumable training with checkpoint saving.\n    \"\"\"\n    model.train()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\n    X, Y = X.to(device), Y.to(device)\n    losses = []\n    start_epoch = 0\n\n    # Try to resume from checkpoint\n    if resume and os.path.exists(checkpoint_path):\n        print(f\"Resuming from checkpoint: {checkpoint_path}\")\n        checkpoint = torch.load(checkpoint_path, weights_only=False)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1\n        losses = checkpoint['losses']\n        print(f\"Resumed from epoch {start_epoch}, previous loss: {losses[-1]:.4f}\")\n\n    for epoch in range(start_epoch, epochs):\n        perm = torch.randperm(X.shape[0])\n        total_loss, n_batches = 0, 0\n\n        for i in range(0, len(X), batch_size):\n            idx = perm[i:i+batch_size]\n            x_batch, y_batch = X[idx], Y[idx]\n\n            logits = model(x_batch)\n            loss = F.cross_entropy(logits.view(-1, vocab_size), y_batch.view(-1))\n\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n            total_loss += loss.item()\n            n_batches += 1\n\n        scheduler.step()\n        losses.append(total_loss / n_batches)\n        \n        if epoch % 50 == 0:\n            print(f\"Epoch {epoch}: Loss = {losses[-1]:.4f}\")\n        \n        # Save checkpoint every 25 epochs\n        if (epoch + 1) % 25 == 0:\n            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'losses': losses,\n            }, checkpoint_path)\n\n    print(f\"Training complete! Final loss: {losses[-1]:.4f}\")\n    return losses\n\n# Educational note: 150 epochs on small model for fast demo\n# For production: larger model and 1000+ epochs\n# Training is resumable - interrupt and re-run this cell to continue!\nprint(\"Training on Python code (resumable)...\")\nlosses = train(model, X, Y, epochs=150, batch_size=64, lr=3e-4)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(10, 4))\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Python Code Model Training Loss')\nplt.grid(True, alpha=0.3)\n# Show number of epochs trained\nplt.text(0.02, 0.98, f'Total epochs: {len(losses)}', \n         transform=plt.gca().transAxes, verticalalignment='top',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\nplt.show()\n\nprint(f\"Training summary: {len(losses)} epochs completed, final loss: {losses[-1]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 6: Code Generation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_code(model, prompt, max_tokens=200, temperature=0.8):\n",
    "    \"\"\"Generate Python code from a prompt.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    tokens = [stoi.get(ch, 0) for ch in prompt]\n",
    "    generated = list(prompt)\n",
    "    \n",
    "    for _ in range(max_tokens):\n",
    "        context = tokens[-block_size:] if len(tokens) >= block_size else tokens\n",
    "        x = torch.tensor([context]).to(device)\n",
    "        \n",
    "        logits = model(x)[0, -1, :] / temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        \n",
    "        tokens.append(next_idx)\n",
    "        generated.append(itos[next_idx])\n",
    "        \n",
    "        # Stop at double newline (end of function)\n",
    "        if ''.join(generated[-3:]) == '\\n\\n\\n':\n",
    "            break\n",
    "    \n",
    "    return ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code completion\n",
    "print(\"=\" * 60)\n",
    "print(\"CODE COMPLETION EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompts = [\n",
    "    'def is_even(n):\\n    \"\"\"',\n",
    "    'def factorial(n):\\n    \"\"\"',\n",
    "    'def reverse_string(s):\\n    \"\"\"',\n",
    "    'def find_max(numbers):\\n    \"\"\"',\n",
    "    'class Stack:\\n    \"\"\"',\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\n--- Prompt: ---\")\n",
    "    print(prompt)\n",
    "    print(f\"--- Generated: ---\")\n",
    "    print(generate_code(model, prompt, max_tokens=150, temperature=0.7))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from function signature\n",
    "print(\"=\" * 60)\n",
    "print(\"GENERATING FROM SIGNATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "signatures = [\n",
    "    'def add(a, b):',\n",
    "    'def is_prime(n):',\n",
    "    'def sum_list(numbers):',\n",
    "    'def binary_search(arr, target):',\n",
    "]\n",
    "\n",
    "for sig in signatures:\n",
    "    print(f\"\\n{sig}\")\n",
    "    result = generate_code(model, sig + '\\n', max_tokens=200, temperature=0.6)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 7: Testing Generated Code\n",
    "\n",
    "The amazing thing about code generation is we can actually **test** if the code works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generated_code(model, function_name, test_cases, temperature=0.6):\n",
    "    \"\"\"\n",
    "    Generate a function and test it.\n",
    "    \n",
    "    Args:\n",
    "        function_name: Name of function to generate\n",
    "        test_cases: List of (input, expected_output) tuples\n",
    "    \"\"\"\n",
    "    # Generate the function\n",
    "    prompt = f\"def {function_name}\"\n",
    "    generated = generate_code(model, prompt, max_tokens=200, temperature=temperature)\n",
    "    \n",
    "    print(f\"Generated code:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(generated)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Try to execute it\n",
    "    try:\n",
    "        exec(generated, globals())\n",
    "        print(\"Code executed successfully!\")\n",
    "        \n",
    "        # Run test cases\n",
    "        func = eval(function_name.split('(')[0])\n",
    "        passed = 0\n",
    "        for inputs, expected in test_cases:\n",
    "            try:\n",
    "                if isinstance(inputs, tuple):\n",
    "                    result = func(*inputs)\n",
    "                else:\n",
    "                    result = func(inputs)\n",
    "                    \n",
    "                if result == expected:\n",
    "                    print(f\"  PASS: {function_name.split('(')[0]}({inputs}) = {result}\")\n",
    "                    passed += 1\n",
    "                else:\n",
    "                    print(f\"  FAIL: {function_name.split('(')[0]}({inputs}) = {result}, expected {expected}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR: {e}\")\n",
    "        \n",
    "        print(f\"\\nPassed {passed}/{len(test_cases)} tests\")\n",
    "        \n",
    "    except SyntaxError as e:\n",
    "        print(f\"Syntax error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test is_even function\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTING: is_even\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_generated_code(\n",
    "    model,\n",
    "    \"is_even(n):\",\n",
    "    [\n",
    "        (2, True),\n",
    "        (3, False),\n",
    "        (0, True),\n",
    "        (7, False),\n",
    "        (100, True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test factorial function\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING: factorial\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_generated_code(\n",
    "    model,\n",
    "    \"factorial(n):\",\n",
    "    [\n",
    "        (0, 1),\n",
    "        (1, 1),\n",
    "        (5, 120),\n",
    "        (3, 6),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reverse_string function\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING: reverse_string\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_generated_code(\n",
    "    model,\n",
    "    \"reverse_string(s):\",\n",
    "    [\n",
    "        (\"hello\", \"olleh\"),\n",
    "        (\"python\", \"nohtyp\"),\n",
    "        (\"\", \"\"),\n",
    "        (\"a\", \"a\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Step 8: Code Understanding - Fill in the Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the model complete partial code?\n",
    "print(\"=\" * 60)\n",
    "print(\"FILL IN THE BLANK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "partial_code = [\n",
    "    \"for i in range(10):\\n    print(\",\n",
    "    \"if x > 0:\\n    return \",\n",
    "    \"numbers = [1, 2, 3]\\ntotal = sum(\",\n",
    "    \"with open('file.txt', '\",\n",
    "]\n",
    "\n",
    "for code in partial_code:\n",
    "    print(f\"\\nInput: {repr(code)}\")\n",
    "    result = generate_code(model, code, max_tokens=20, temperature=0.5)\n",
    "    # Show just the completion\n",
    "    completion = result[len(code):].split('\\n')[0]\n",
    "    print(f\"Completion: {repr(completion)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save model checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'vocab_size': vocab_size,\n",
    "        'd_model': d_model,\n",
    "        'n_heads': n_heads,\n",
    "        'n_layers': n_layers,\n",
    "        'block_size': block_size,\n",
    "    },\n",
    "    'stoi': stoi,\n",
    "    'itos': itos,\n",
    "    'final_loss': losses[-1] if losses else None,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, '../models/python_code_lm.pt')\n",
    "print(f\"Model saved to ../models/python_code_lm.pt\")\n",
    "print(f\"Model parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Clean Up GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "del X, Y\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"GPU memory cleared!\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## What Makes Code Generation Special\n",
    "\n",
    "| Aspect | Natural Language | Code |\n",
    "|--------|------------------|------|\n",
    "| Syntax | Flexible | Strict (one typo = error) |\n",
    "| Verification | Subjective | Objective (runs or not) |\n",
    "| Structure | Varied | Consistent patterns |\n",
    "| Evaluation | Human judgment | Automated testing |\n",
    "| Context | Loose dependencies | Precise scope rules |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We trained a Python code generation model that can:\n",
    "\n",
    "1. **Complete function signatures** with implementations\n",
    "2. **Generate docstrings** from function names\n",
    "3. **Fill in code** given partial context\n",
    "4. **Produce runnable code** (sometimes!)\n",
    "\n",
    "| Component | What We Did |\n",
    "|-----------|-------------|\n",
    "| Training data | ~500 lines of Python functions |\n",
    "| Model | Transformer with 6 layers, 256 dim |\n",
    "| Vocabulary | Character-level (~60 chars) |\n",
    "| Evaluation | Actually running the generated code! |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## The Complete 7-Part Series\n",
    "\n",
    "```\n",
    "Part 1: Character-Level LM      → Basic next-token prediction\n",
    "Part 2: Shakespeare             → Same model, different domain  \n",
    "Part 3: BPE Tokenizer           → Efficient subword tokenization\n",
    "Part 4: Self-Attention          → Transformer architecture\n",
    "Part 5: Instruction Tuning      → Following instructions\n",
    "Part 6: DPO Alignment           → Learning preferences\n",
    "Part 7: Python Code             → Practical code generation\n",
    "```\n",
    "\n",
    "You now have a complete understanding of how modern LLMs work, from basic language modeling to code generation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **More training data**: Add more Python functions. Does quality improve?\n",
    "2. **BPE for code**: Apply BPE tokenization to code. How does it compare?\n",
    "3. **Indentation handling**: Code relies heavily on indentation. Can you improve this?\n",
    "4. **Test-driven generation**: Given test cases, generate the function\n",
    "5. **Multi-file context**: How would you handle imports and multi-file projects?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}